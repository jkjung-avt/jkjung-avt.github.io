---
layout: post
comments: true
title: "YOLOv3 on Jetson TX2"
excerpt: "Recently I looked at darknet web site again and surprising found there was an updated version of YOLO , i.e. YOLOv3. So I spent a little time testing it on Jetson TX2. Here is the result."
date: 2018-03-27
category: "yolo"
tags: yolo
---

Recenetly I looked at [darknet](https://pjreddie.com/darknet/yolo/) web site again and surprising found there was an updated version of YOLO , i.e. **YOLOv3**. So I spent a little time testing it on Jetson TX2. Here is the result.

A while ago I wrote a post about YOLOv2, ["YOLOv2 on Jetson TX2"](https://jkjung-avt.github.io/yolov2/). And **YOLOv3** seems to be an improved version of YOLO in terms of both accuracy and speed. Check out the following paper for details of the improvements.

* [YOLOv3: An Incremental Improvement](https://pjreddie.com/media/files/papers/YOLOv3.pdf)

Here is how I installed and tested YOLOv3 on Jetson TX2.

# Prerequisite

I tested YOLOv3 on a Jetson TX2 with **JetPack-3.2**. In order to test YOLOv3 with video files and live camera feed, I had to first install **opencv-3.4.0** on the Jetson TX2. Reference: [How to Install OpenCV (3.4.0) on Jetson TX2](https://jkjung-avt.github.io/opencv3-on-tx2/)

Note that YOLOv3 could not be compiled against opencv-3.4.1 due to [this problem](https://github.com/opencv/opencv/issues/10963) (/usr/include/opencv2/core/cvdef.h:485:1: error: unknown type name 'namespace'). So be sure to use **opencv-3.4.0** when building YOLOv3.

# Step-by-step

1. Clone the latest darknet source code from GitHub.

   ```shell
   $ cd ~/project 
   $ git clone https://github.com/pjreddie/darknet yolov3
   $ cd yolov3
   ```

2. Modify the first few lines of `Makefile` as follows. Note that CUDA architecture of TX2 is "62", while TX1 "53".

   ```
   GPU=1
   CUDNN=1
   OPENCV=1
   ......
   ARCH= -gencode arch=compute_53,code=[sm_53,compute_53] \
         -gencode arch=compute_62,code=[sm_62,compute_62]
   ```

3. Build the code.

   ```shell
   $ make
   ```

4. I first tested YOLOv3 with [this YouTube video](https://youtu.be/wqctLW0Hb_0). I downloaded the video from YouTube and saved it as `traffic.mp4`. Then I ran YOLOv3 with pre-trained weights (with the COCO dataset) over the video file. And I got **3~3.3 frames per second**, while the object detection results looked OK.

   ```shell
   ### set TX2 to max performance mode
   $ sudo nvpmodel -m 0
   $ sudo ~/jetson_clocks.sh
   ### download the pre-trained weights and run YOLOv3
   $ wget https://pjreddie.com/media/files/yolov3.weights
   $ ./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights \
                             traffic.mp4
   ```

   ![yolov3 testing screenshot](/assets/2018-03-27-yolov3/yolov3-test.png)

5. I also tested YOLOv3 with live video feed from a USB webcam. The result was similar at 3~3.3 fps. Note in the command below, the `-c 1` means using the camera (V4L2) device at `/dev/video1`.

   ```shell
   $ ./darknet detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights \
                             -c 1
   ```

Overall, YOLOv3 did seem better than YOLOv2. When running YOLOv2, I often saw the bounding boxes jittering around objects constantly. While with YOLOv3, the bounding boxes looked more stable and accurate. The processing speed of YOLOv3 (3~3.3 fps on TX2) was not up for practical use though. I wondered whether it was due to its implementaion in darknet. I might try out some caffe implementation of YOLOv3 when I have time.
